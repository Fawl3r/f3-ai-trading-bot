#!/usr/bin/env python3
"""
Elite Walk-Forward Backtesting System - Double-Up Strategy
Comprehensive backtesting with strict validation gates for 70%+ win rate
"""

import numpy as np
import pandas as pd
from pathlib import Path
import logging
from datetime import datetime, timedelta
import joblib
import json
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# ML Libraries
import lightgbm as lgb
import catboost as cb
import torch
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score, classification_report

# Custom modules
import sys
sys.path.append('..')
from models.elite_ai_trainer import BiLSTMModel, TransformerModel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EliteWalkForwardBacktest:
    """Elite walk-forward backtesting system"""
    
    def __init__(self, 
                 data_dir: Path = Path("data/processed"),
                 models_dir: Path = Path("models/trained"),
                 risk_per_trade: float = 0.0075,  # 0.75% risk per trade
                 risk_reward_ratio: float = 4.0):
        
        self.data_dir = data_dir
        self.models_dir = models_dir
        self.risk_per_trade = risk_per_trade
        self.risk_reward_ratio = risk_reward_ratio
        
        # Validation gates
        self.validation_gates = {
            'expectancy_min': 0.003,      # +0.30% per trade
            'profit_factor_min': 1.30,    # 1.30 or higher
            'max_drawdown_max': 0.05,     # 5% max drawdown
            'sharpe_min': 1.0,            # Sharpe ratio >= 1.0
            'min_trades': 100             # Minimum 100 trades
        }
        
        # Performance tracking
        self.results = {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
    def load_models(self, coin: str) -> Dict:
        """Load trained models for a coin"""
        models_path = self.models_dir / coin
        
        if not models_path.exists():
            raise FileNotFoundError(f"Models not found for {coin}")
        
        models = {}
        
        # Load tree-based models
        for model_name in ['lightgbm', 'catboost', 'ensemble']:
            model_file = models_path / f"{model_name}_model.pkl"
            if model_file.exists():
                models[model_name] = joblib.load(model_file)
        
        # Load deep learning models
        for model_name in ['bilstm', 'transformer']:
            model_file = models_path / f"{model_name}_model.pth"
            if model_file.exists():
                # Load metadata to get input size
                metadata = joblib.load(self.data_dir / coin / "metadata.pkl")
                input_size = len(metadata['feature_names'])
                
                if model_name == 'bilstm':
                    model = BiLSTMModel(input_size=input_size).to(self.device)
                elif model_name == 'transformer':
                    model = TransformerModel(input_size=input_size).to(self.device)
                
                model.load_state_dict(torch.load(model_file, map_location=self.device))
                model.eval()
                models[model_name] = model
        
        logger.info(f"üìä Loaded {len(models)} models for {coin}")
        return models
    
    def load_data(self, coin: str) -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:
        """Load data for backtesting"""
        coin_dir = self.data_dir / coin
        
        X = np.load(coin_dir / "X.npy")
        y = np.load(coin_dir / "y.npy")
        
        # Load raw data for price information
        raw_data_file = None
        for file in (Path("data/raw") / coin / "1m").glob("*.parquet"):
            raw_data_file = file
            break
        
        if raw_data_file:
            raw_data = pd.read_parquet(raw_data_file)
        else:
            raw_data = pd.DataFrame()
        
        return X, y, raw_data
    
    def get_ensemble_prediction(self, models: Dict, X_sample: np.ndarray) -> float:
        """Get ensemble prediction for a single sample"""
        predictions = []
        
        # Flatten for tree-based models
        X_flat = X_sample.reshape(1, -1)
        
        for name, model in models.items():
            if name == 'ensemble':
                continue  # Skip ensemble meta-learner for now
            
            if name == 'lightgbm':
                pred = model.predict(X_flat)[0]
            elif name == 'catboost':
                pred = model.predict_proba(X_flat)[0, 1]
            elif name in ['bilstm', 'transformer']:
                with torch.no_grad():
                    X_tensor = torch.FloatTensor(X_sample).unsqueeze(0).to(self.device)
                    outputs = model(X_tensor)
                    pred = F.softmax(outputs, dim=1)[0, 1].cpu().numpy()
            else:
                continue
            
            predictions.append(pred)
        
        # Simple average ensemble
        if predictions:
            return np.mean(predictions)
        else:
            return 0.5
    
    def simulate_trade(self, entry_price: float, prediction: float, 
                      future_prices: np.ndarray, atr: float) -> Dict:
        """Simulate a single trade"""
        
        # Only trade if prediction is confident
        if prediction < 0.6:  # 60% confidence threshold
            return {'trade_taken': False}
        
        # Calculate stop loss and take profit
        stop_loss = entry_price - atr
        take_profit = entry_price + (atr * self.risk_reward_ratio)
        
        # Simulate trade outcome
        for i, price in enumerate(future_prices):
            if price <= stop_loss:
                # Stop loss hit
                return {
                    'trade_taken': True,
                    'outcome': 'loss',
                    'pnl_r': -1.0,  # -1R
                    'pnl_pct': -self.risk_per_trade,
                    'bars_held': i + 1,
                    'exit_price': stop_loss
                }
            elif price >= take_profit:
                # Take profit hit
                return {
                    'trade_taken': True,
                    'outcome': 'win',
                    'pnl_r': self.risk_reward_ratio,  # +4R
                    'pnl_pct': self.risk_per_trade * self.risk_reward_ratio,
                    'bars_held': i + 1,
                    'exit_price': take_profit
                }
        
        # No exit hit within timeframe
        return {
            'trade_taken': True,
            'outcome': 'timeout',
            'pnl_r': 0.0,
            'pnl_pct': 0.0,
            'bars_held': len(future_prices),
            'exit_price': entry_price
        }
    
    def run_walk_forward_window(self, coin: str, X: np.ndarray, y: np.ndarray, 
                               raw_data: pd.DataFrame, window_start: int, 
                               window_size: int = 5000) -> Dict:
        """Run backtest for a single walk-forward window"""
        
        # Define window bounds
        window_end = min(window_start + window_size, len(X))
        
        if window_end - window_start < 1000:
            return {'trades': [], 'error': 'Window too small'}
        
        logger.info(f"üìä Processing window {window_start}-{window_end} ({window_end - window_start} samples)")
        
        # Load models
        try:
            models = self.load_models(coin)
        except Exception as e:
            return {'trades': [], 'error': f'Model loading failed: {e}'}
        
        # Get window data
        X_window = X[window_start:window_end]
        y_window = y[window_start:window_end]
        
        # Align with raw data if available
        if len(raw_data) > 0 and len(raw_data) >= window_end:
            raw_window = raw_data.iloc[window_start:window_end]
        else:
            raw_window = pd.DataFrame()
        
        trades = []
        
        # Process each sample in window
        for i in range(len(X_window) - 100):  # Leave 100 bars for trade simulation
            try:
                # Get prediction
                prediction = self.get_ensemble_prediction(models, X_window[i])
                
                # Get price data
                if len(raw_window) > i:
                    entry_price = raw_window.iloc[i]['close']
                    atr = raw_window.iloc[i]['high'] - raw_window.iloc[i]['low']  # Simple ATR approximation
                    
                    # Get future prices for trade simulation
                    future_high = raw_window.iloc[i+1:i+101]['high'].values
                    future_low = raw_window.iloc[i+1:i+101]['low'].values
                    future_prices = np.column_stack([future_high, future_low]).flatten()
                else:
                    # Fallback if no raw data
                    entry_price = 100.0
                    atr = 2.0
                    future_prices = np.random.normal(entry_price, atr, 200)
                
                # Simulate trade
                trade_result = self.simulate_trade(entry_price, prediction, future_prices, atr)
                
                if trade_result['trade_taken']:
                    trade_result.update({
                        'timestamp': window_start + i,
                        'entry_price': entry_price,
                        'prediction': prediction,
                        'actual_label': y_window[i],
                        'atr': atr
                    })
                    trades.append(trade_result)
                
            except Exception as e:
                logger.error(f"Error processing sample {i}: {e}")
                continue
        
        return {'trades': trades, 'error': None}
    
    def calculate_performance_metrics(self, trades: List[Dict]) -> Dict:
        """Calculate comprehensive performance metrics"""
        if not trades:
            return {'error': 'No trades to analyze'}
        
        # Filter out timeouts for main metrics
        completed_trades = [t for t in trades if t['outcome'] != 'timeout']
        
        if not completed_trades:
            return {'error': 'No completed trades'}
        
        # Basic metrics
        total_trades = len(completed_trades)
        winning_trades = len([t for t in completed_trades if t['outcome'] == 'win'])
        losing_trades = len([t for t in completed_trades if t['outcome'] == 'loss'])
        
        win_rate = winning_trades / total_trades if total_trades > 0 else 0
        
        # PnL metrics
        pnl_r = [t['pnl_r'] for t in completed_trades]
        pnl_pct = [t['pnl_pct'] for t in completed_trades]
        
        total_pnl_r = sum(pnl_r)
        total_pnl_pct = sum(pnl_pct)
        
        # Expectancy
        expectancy_r = np.mean(pnl_r) if pnl_r else 0
        expectancy_pct = np.mean(pnl_pct) if pnl_pct else 0
        
        # Profit factor
        gross_profit = sum([p for p in pnl_r if p > 0])
        gross_loss = abs(sum([p for p in pnl_r if p < 0]))
        profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf')
        
        # Drawdown calculation
        cumulative_pnl = np.cumsum(pnl_r)
        running_max = np.maximum.accumulate(cumulative_pnl)
        drawdown = (cumulative_pnl - running_max) / np.maximum(running_max, 1)
        max_drawdown = abs(np.min(drawdown))
        
        # Sharpe ratio (assuming 252 trading days)
        if len(pnl_r) > 1:
            sharpe_ratio = np.mean(pnl_r) / np.std(pnl_r) * np.sqrt(252) if np.std(pnl_r) > 0 else 0
        else:
            sharpe_ratio = 0
        
        # Average holding period
        avg_holding_period = np.mean([t['bars_held'] for t in completed_trades])
        
        return {
            'total_trades': total_trades,
            'winning_trades': winning_trades,
            'losing_trades': losing_trades,
            'win_rate': win_rate,
            'expectancy_r': expectancy_r,
            'expectancy_pct': expectancy_pct,
            'total_pnl_r': total_pnl_r,
            'total_pnl_pct': total_pnl_pct,
            'profit_factor': profit_factor,
            'max_drawdown': max_drawdown,
            'sharpe_ratio': sharpe_ratio,
            'avg_holding_period': avg_holding_period,
            'gross_profit': gross_profit,
            'gross_loss': gross_loss
        }
    
    def validate_against_gates(self, metrics: Dict) -> Dict:
        """Validate metrics against elite gates"""
        if 'error' in metrics:
            return {'passed': False, 'reason': metrics['error']}
        
        gates_passed = {}
        
        # Check each gate
        gates_passed['min_trades'] = metrics['total_trades'] >= self.validation_gates['min_trades']
        gates_passed['expectancy'] = metrics['expectancy_pct'] >= self.validation_gates['expectancy_min']
        gates_passed['profit_factor'] = metrics['profit_factor'] >= self.validation_gates['profit_factor_min']
        gates_passed['max_drawdown'] = metrics['max_drawdown'] <= self.validation_gates['max_drawdown_max']
        gates_passed['sharpe_ratio'] = metrics['sharpe_ratio'] >= self.validation_gates['sharpe_min']
        
        all_passed = all(gates_passed.values())
        
        failed_gates = [gate for gate, passed in gates_passed.items() if not passed]
        
        return {
            'passed': all_passed,
            'gates_passed': gates_passed,
            'failed_gates': failed_gates,
            'reason': f"Failed gates: {failed_gates}" if failed_gates else "All gates passed"
        }
    
    def run_full_backtest(self, coin: str, window_size: int = 5000, 
                         shift_size: int = 3000) -> Dict:
        """Run complete walk-forward backtest"""
        logger.info(f"üöÄ Starting elite backtest for {coin}")
        
        # Load data
        try:
            X, y, raw_data = self.load_data(coin)
        except Exception as e:
            return {'error': f'Data loading failed: {e}'}
        
        logger.info(f"üìä Data loaded: {len(X)} samples")
        
        # Calculate number of windows
        total_windows = (len(X) - window_size) // shift_size + 1
        logger.info(f"üìà Running {total_windows} walk-forward windows")
        
        all_trades = []
        window_results = []
        
        # Run walk-forward windows
        for window_idx in range(total_windows):
            window_start = window_idx * shift_size
            
            logger.info(f"\nüìä Window {window_idx + 1}/{total_windows}")
            
            # Run window
            window_result = self.run_walk_forward_window(
                coin, X, y, raw_data, window_start, window_size
            )
            
            if window_result['error']:
                logger.error(f"Window {window_idx + 1} failed: {window_result['error']}")
                continue
            
            # Calculate metrics for this window
            window_metrics = self.calculate_performance_metrics(window_result['trades'])
            
            if 'error' not in window_metrics:
                # Validate against gates
                validation = self.validate_against_gates(window_metrics)
                
                window_summary = {
                    'window_idx': window_idx,
                    'window_start': window_start,
                    'trades': len(window_result['trades']),
                    'win_rate': window_metrics['win_rate'],
                    'expectancy_pct': window_metrics['expectancy_pct'],
                    'profit_factor': window_metrics['profit_factor'],
                    'max_drawdown': window_metrics['max_drawdown'],
                    'sharpe_ratio': window_metrics['sharpe_ratio'],
                    'gates_passed': validation['passed']
                }
                
                window_results.append(window_summary)
                all_trades.extend(window_result['trades'])
                
                logger.info(f"  Trades: {window_summary['trades']}")
                logger.info(f"  Win Rate: {window_summary['win_rate']:.1%}")
                logger.info(f"  Expectancy: {window_summary['expectancy_pct']:.3%}")
                logger.info(f"  Gates: {'‚úÖ PASSED' if validation['passed'] else '‚ùå FAILED'}")
        
        # Calculate overall metrics
        overall_metrics = self.calculate_performance_metrics(all_trades)
        
        if 'error' in overall_metrics:
            return {'error': overall_metrics['error']}
        
        # Final validation
        final_validation = self.validate_against_gates(overall_metrics)
        
        return {
            'coin': coin,
            'overall_metrics': overall_metrics,
            'validation': final_validation,
            'window_results': window_results,
            'total_trades': len(all_trades),
            'windows_passed': len([w for w in window_results if w['gates_passed']]),
            'total_windows': len(window_results)
        }
    
    def run_multi_coin_backtest(self, coins: List[str]) -> Dict:
        """Run backtest across multiple coins"""
        logger.info(f"üéØ Running elite multi-coin backtest for {coins}")
        
        results = {}
        
        for coin in coins:
            logger.info(f"\n{'='*50}")
            logger.info(f"BACKTESTING {coin}")
            logger.info(f"{'='*50}")
            
            try:
                coin_result = self.run_full_backtest(coin)
                results[coin] = coin_result
                
                if 'error' not in coin_result:
                    metrics = coin_result['overall_metrics']
                    validation = coin_result['validation']
                    
                    logger.info(f"\nüìä {coin} RESULTS:")
                    logger.info(f"  Total Trades: {metrics['total_trades']}")
                    logger.info(f"  Win Rate: {metrics['win_rate']:.1%}")
                    logger.info(f"  Expectancy: {metrics['expectancy_pct']:.3%}")
                    logger.info(f"  Profit Factor: {metrics['profit_factor']:.2f}")
                    logger.info(f"  Max Drawdown: {metrics['max_drawdown']:.1%}")
                    logger.info(f"  Sharpe Ratio: {metrics['sharpe_ratio']:.2f}")
                    logger.info(f"  Validation: {'‚úÖ PASSED' if validation['passed'] else '‚ùå FAILED'}")
                    
                    if not validation['passed']:
                        logger.info(f"  Failed Gates: {validation['failed_gates']}")
                
            except Exception as e:
                logger.error(f"‚ùå Error backtesting {coin}: {e}")
                results[coin] = {'error': str(e)}
        
        return results
    
    def save_results(self, results: Dict, output_file: str = "elite_backtest_results.json"):
        """Save backtest results"""
        output_path = Path(output_file)
        
        # Convert numpy types to Python types for JSON serialization
        def convert_numpy(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_numpy(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy(item) for item in obj]
            else:
                return obj
        
        results_clean = convert_numpy(results)
        
        with open(output_path, 'w') as f:
            json.dump(results_clean, f, indent=2)
        
        logger.info(f"üíæ Results saved to {output_path}")

def main():
    """Main backtesting pipeline"""
    backtest = EliteWalkForwardBacktest(risk_per_trade=0.0075)  # 0.75% risk for double-up
    
    # Elite coins for double-up strategy
    elite_coins = ['SOL', 'BTC', 'ETH']
    
    # Run multi-coin backtest
    results = backtest.run_multi_coin_backtest(elite_coins)
    
    # Save results
    backtest.save_results(results, "elite_double_up_backtest_results.json")
    
    # Summary
    print(f"\n{'='*50}")
    print("ELITE WALK-FORWARD BACKTEST COMPLETE")
    print(f"{'='*50}")
    
    passed_coins = []
    failed_coins = []
    
    for coin, result in results.items():
        if 'error' in result:
            failed_coins.append(coin)
            print(f"‚ùå {coin}: {result['error']}")
        else:
            if result['validation']['passed']:
                passed_coins.append(coin)
                print(f"‚úÖ {coin}: PASSED ALL GATES")
            else:
                failed_coins.append(coin)
                print(f"‚ùå {coin}: FAILED - {result['validation']['reason']}")
    
    print(f"\nüéØ SUMMARY:")
    print(f"  Passed: {len(passed_coins)} coins - {passed_coins}")
    print(f"  Failed: {len(failed_coins)} coins - {failed_coins}")
    
    if passed_coins:
        print(f"\nüöÄ Ready for live deployment with: {passed_coins}")
    else:
        print(f"\n‚ö†Ô∏è  No coins passed all gates. Review model training.")

if __name__ == "__main__":
    main() 